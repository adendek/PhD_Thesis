% the abstract

Niniejsza rozprawa doktorska składa się z opisu dwóch projektów badawczych zrealizowanych w ramach współpracy LHCb. Pierwszy z nich jest dedykowana opisowi prac nad algorytmem do rekonstrukcji śladów pochodzących od cząstek długożyciowych. W ramach prowadzonych badań zdecydowano się zastosować nowatorskie metody uczenia maszynowego w celu poprawy czystości i wydajności rekonstrukcji. Projekt ten jest jednym z pierwszych, który używa zaawansowanych modeli uczenia maszynowego w ramach systemu wyzwalania (tryggera) wysokiego poziomu. W ramach studiów nad analizą wydajności testowanych modeli wykonano nowatorską analizę interpretowalności predykcji złożonych modeli uczenia maszynowego. 

 Druga część pracy przedstawia zaprojektowanie i zaimplementowanie platformy do emulacji i monitoringu algorytmów przetwarzania surowych danych zbieranych przez projektowany detektor UT (ang. Upstream Tracker) w ramach modernizacji detektora LHCb. W wyniku tych prac została dostarczona aplikacja TbUT. Aplikacja ta była wykorzystywana podczas szeregu testów na wiązce, których celem było sprawdzenie poprawności projektowanych sensorów oraz elektronicznego układu odczytu front-end Salt. W przyszłości oprogramowanie to będzie wykorzystywane między innymi do wykonywania kalibracji i monitorowania poprawności działania detektora UT.  


Rozprawa doktorska rozpoczyna się od wstępu, który skupia się przedstawieniu eksperymentu LHCb oraz wyjaśnieniu zasady działania każdego z elementów detektora, jak również motywacji do jego modernizacji. W kolejnym rozdziale zostały przedstawione aspekty teoretyczne dotyczące Modelu Standardowego ze szczególnym uwzględnieniem oddziaływań słabych oraz problemu łamania symetrii kombinowanej $CP$, będącej motywacją do powstania eksperymentu LHCb. Rozdział trzeci skupia się na przedstawieniu i dogłębnej analizie algorytmów uczenia maszynowego. Dyskutowane są zarówno matematyczne podstawy wybranych modeli, jak również procesu ich trenowania oraz optymalizacji ich hiper parametrów. Czwarty rozdział jest dedykowany przedstawieniu prac w ramach poprawy algorytmu rekonstrukcji śladów cząstek długożyciowych. Rozdział ten składa się z przedstawienia algorytmu rozpoznawania wzorców oraz studiów nad dwoma klasyfikatorami opartymi o algorytmy uczenia maszynowego. Rozdział piąty przedstawia wstęp teoretyczny dotyczący oddziaływania promieniowania oraz materii, czy zasady działania krzemowego detektora promieniowania jonizującego, po czym przedstawione jest oprogramowanie TbUT. Szósty rozdział przedstawia analizę danych zebranych podczas testów na wiązce w szczególności skupiając się na problemie współdzielenia ładunku. Rozprawa kończy się  podsumowaniem i wnioskami zebranymi w rozdziale siódmym. 
